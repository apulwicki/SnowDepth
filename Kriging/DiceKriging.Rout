
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ############################################################################
> #Dice Kriging
> ############################################################################
> 
> ## Libraries
> library(R.matlab)
R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help.

Attaching package: ‘R.matlab’

The following objects are masked from ‘package:base’:

    getOption, isOpen

> library(DiceKriging)
> library(DiceOptim)
> library(foreach)
> 
> 
> ## Load my data ##
> #residuals = readMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/residuals.mat')
> residuals = readMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/residuals.mat')
> res = residuals$res
> utm = data.frame(residuals$utm)
> sizexy = residuals$sizexy
> 
> ## Model ##
> m = km(~1,design = utm, response = res, covtype = "matern5_2", nugget.estim = TRUE, multistart = 5, iso = TRUE)

optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern5_2 
  - nugget : unknown homogenous nugget effect 
  - parameters lower bounds :  1e-10 
  - parameters upper bounds :  5128.1 
  - upper bound for alpha   :  1 
  - best initial criterion value(s) :  160.1529 155.0455 142.5957 140.7159 137.9748 

N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -160.15  |proj g|=       0.4265
At iterate     1  f =      -169.04  |proj g|=      0.046969
At iterate     2  f =      -169.06  |proj g|=      0.042578
At iterate     3  f =      -169.06  |proj g|=       0.14394
At iterate     4  f =      -169.06  |proj g|=      0.013636
At iterate     5  f =      -169.06  |proj g|=      0.077741
At iterate     6  f =      -169.06  |proj g|=       0.20299
At iterate     7  f =      -169.06  |proj g|=        0.5362
At iterate     8  f =      -169.06  |proj g|=       0.95837
At iterate     9  f =      -169.06  |proj g|=       0.95878
At iterate    10  f =      -169.07  |proj g|=        0.9594
At iterate    11  f =      -169.07  |proj g|=       0.96038
At iterate    12  f =      -169.08  |proj g|=       0.96185
At iterate    13  f =      -169.12  |proj g|=       0.96391
At iterate    14  f =      -169.24  |proj g|=       0.96641
At iterate    15  f =      -169.59  |proj g|=       0.96802
At iterate    16  f =      -170.45  |proj g|=       0.96305
At iterate    17  f =      -171.37  |proj g|=       0.94836
At iterate    18  f =      -172.97  |proj g|=       0.91996
At iterate    19  f =      -173.99  |proj g|=       0.88477
At iterate    20  f =      -175.33  |proj g|=       0.82434
At iterate    21  f =      -182.13  |proj g|=       0.64965
At iterate    22  f =      -182.44  |proj g|=       0.62108
At iterate    23  f =      -182.59  |proj g|=      0.068125
At iterate    24  f =      -182.59  |proj g|=     0.0040724
At iterate    25  f =      -182.59  |proj g|=     2.899e-05
At iterate    26  f =      -182.59  |proj g|=    1.9033e-07

iterations 26
function evaluations 44
segments explored during Cauchy searches 29
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.90335e-07
final function value -182.592

F = -182.592
final  value -182.591508 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -155.05  |proj g|=      0.49791
At iterate     1  f =      -166.87  |proj g|=      0.037138
At iterate     2  f =      -166.93  |proj g|=       0.97526
At iterate     3  f =      -166.95  |proj g|=      0.030226
At iterate     4  f =      -166.95  |proj g|=      0.028746
At iterate     5  f =      -166.95  |proj g|=       0.11993
At iterate     6  f =      -166.95  |proj g|=      0.012056
At iterate     7  f =      -166.95  |proj g|=       0.02305
At iterate     8  f =      -166.95  |proj g|=       0.12511
At iterate     9  f =      -166.95  |proj g|=       0.28102
At iterate    10  f =      -166.95  |proj g|=       0.54046
At iterate    11  f =      -166.95  |proj g|=       0.96015
At iterate    12  f =      -166.95  |proj g|=       0.97214
At iterate    13  f =      -166.95  |proj g|=       0.97248
At iterate    14  f =      -166.96  |proj g|=       0.97302
At iterate    15  f =      -166.96  |proj g|=       0.97387
At iterate    16  f =      -166.98  |proj g|=       0.97515
At iterate    17  f =      -167.03  |proj g|=       0.97698
At iterate    18  f =      -167.19  |proj g|=       0.97926
At iterate    19  f =      -167.68  |proj g|=       0.98095
At iterate    20  f =      -168.73  |proj g|=       0.97693
At iterate    21  f =      -169.95  |proj g|=       0.96689
At iterate    22  f =      -171.47  |proj g|=       0.95003
At iterate    23  f =      -172.56  |proj g|=       0.92099
At iterate    24  f =       -174.2  |proj g|=       0.88054
At iterate    25  f =      -175.25  |proj g|=       0.82646
At iterate    26  f =      -181.96  |proj g|=       0.66403
At iterate    27  f =      -182.06  |proj g|=       0.65048
At iterate    28  f =      -182.58  |proj g|=       0.60026
At iterate    29  f =      -182.59  |proj g|=      0.022082
At iterate    30  f =      -182.59  |proj g|=      0.018336
At iterate    31  f =      -182.59  |proj g|=    0.00034672
At iterate    32  f =      -182.59  |proj g|=    1.8868e-07

iterations 32
function evaluations 46
segments explored during Cauchy searches 34
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 1.88681e-07
final function value -182.592

F = -182.592
final  value -182.591508 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -142.6  |proj g|=      0.50828
At iterate     1  f =      -159.48  |proj g|=       0.03687
ys=-2.089e+01  -gs= 1.124e+01, BFGS update SKIPPED
At iterate     2  f =      -160.99  |proj g|=      0.012239
At iterate     3  f =      -161.02  |proj g|=      0.010436
At iterate     4  f =      -161.02  |proj g|=       0.53799
At iterate     5  f =      -161.02  |proj g|=      0.007611
At iterate     6  f =      -161.02  |proj g|=     0.0043776

iterations 6
function evaluations 15
segments explored during Cauchy searches 9
BFGS updates skipped 1
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.00437762
final function value -161.019

F = -161.019
final  value -161.018712 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -140.72  |proj g|=      0.52293
At iterate     1  f =       -158.3  |proj g|=      0.037903
ys=-2.764e+01  -gs= 1.068e+01, BFGS update SKIPPED
At iterate     2  f =      -160.31  |proj g|=      0.012567
At iterate     3  f =      -160.44  |proj g|=       0.99163
At iterate     4  f =      -160.44  |proj g|=      0.008776
At iterate     5  f =      -160.44  |proj g|=     0.0086118
At iterate     6  f =      -160.44  |proj g|=     0.0054422
At iterate     7  f =      -160.44  |proj g|=      0.003862

iterations 7
function evaluations 15
segments explored during Cauchy searches 10
BFGS updates skipped 1
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.00386196
final function value -160.438

F = -160.438
final  value -160.437646 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -137.97  |proj g|=      0.52033
At iterate     1  f =      -155.82  |proj g|=       0.03772
ys=-4.103e+01  -gs= 8.959e+00, BFGS update SKIPPED
At iterate     2  f =       -159.2  |proj g|=     0.0086036
At iterate     3  f =      -159.36  |proj g|=     0.0057265
At iterate     4  f =      -159.36  |proj g|=       0.35762
At iterate     5  f =      -159.36  |proj g|=     0.0031041
At iterate     6  f =      -159.36  |proj g|=      0.003299

iterations 6
function evaluations 17
segments explored during Cauchy searches 9
BFGS updates skipped 1
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.00329899
final function value -159.359

F = -159.359
final  value -159.359271 
converged

* The 5 best values (multistart) obtained are:
 -182.5915 -182.5915 -161.0187 -160.4376 -159.3593 
* The model corresponding to the best one (-182.5915) is stored. 
Warning message:
executing %dopar% sequentially: no parallel backend registered 
>  
>  #plot(m)
>  #m
>  
>  #Return model paramaters
>  maxLL = -m@logLik
>  intercept = m@trend.coef
>  nugget = m@covariance@nugget
>  theta = m@covariance@range.val
>     model = data.frame(intercept, nugget, maxLL, theta)
> 
>  #Cross validation (leave one out)
>  LOO = leaveOneOut.km(m, "SK",trend.reestim = TRUE)
>  
>  
> ## Kriging prediction surface ##
> x = seq(from = 0, to = (sizexy[1,2]-1)*40, by = 40)
> y = seq(from = 0, to = (sizexy[1,1]-1)*40, by = 40)
> grid = expand.grid(X1=x, X2 = y)
> pred.m = predict(m,grid,"SK")
