
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ############################################################################
> #Dice Kriging
> ############################################################################
> 
> ## Libraries
> library(R.matlab)
R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help.

Attaching package: ‘R.matlab’

The following objects are masked from ‘package:base’:

    getOption, isOpen

> library(DiceKriging)
> library(DiceOptim)
> library(foreach)
> 
> 
> ## Load my data ##
> #residuals = readMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/residuals.mat')
> residuals = readMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/residuals.mat')
> res = residuals$res
> utm = data.frame(residuals$utm)
> sizexy = residuals$sizexy
> 
> ## Model ##
> m = km(~1,design = utm, response = res, covtype = "matern5_2", nugget.estim = TRUE, multistart = 5, iso = TRUE)

optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern5_2 
  - nugget : unknown homogenous nugget effect 
  - parameters lower bounds :  1e-10 
  - parameters upper bounds :  4916.567 
  - upper bound for alpha   :  1 
  - best initial criterion value(s) :  151.7265 150.1444 145.902 144.1624 138.6886 

N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -151.73  |proj g|=      0.17645
At iterate     1  f =      -152.23  |proj g|=       0.88336
At iterate     2  f =      -152.23  |proj g|=       0.12326
At iterate     3  f =      -152.23  |proj g|=       0.05401
At iterate     4  f =      -152.23  |proj g|=     0.0032651
At iterate     5  f =      -152.23  |proj g|=     0.0032651

iterations 5
function evaluations 7
segments explored during Cauchy searches 6
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.00326506
final function value -152.233

F = -152.233
final  value -152.233355 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -150.14  |proj g|=       0.2066
At iterate     1  f =      -150.47  |proj g|=        0.4384
At iterate     2  f =      -150.47  |proj g|=       0.14041
At iterate     3  f =      -150.47  |proj g|=      0.011399
At iterate     4  f =      -150.47  |proj g|=        0.0114
At iterate     5  f =      -150.47  |proj g|=      0.031853
At iterate     6  f =      -150.47  |proj g|=      0.067424
At iterate     7  f =      -150.47  |proj g|=       0.13428
At iterate     8  f =      -150.47  |proj g|=       0.23729
At iterate     9  f =      -150.47  |proj g|=       0.40895
At iterate    10  f =      -150.47  |proj g|=       0.68866
At iterate    11  f =      -150.48  |proj g|=       0.86661
At iterate    12  f =      -150.48  |proj g|=       0.87062
At iterate    13  f =       -150.5  |proj g|=       0.87748
At iterate    14  f =      -150.55  |proj g|=       0.88937
At iterate    15  f =      -150.67  |proj g|=       0.90864
At iterate    16  f =      -150.96  |proj g|=       0.92173
At iterate    17  f =      -151.44  |proj g|=       0.92242
At iterate    18  f =      -151.97  |proj g|=       0.90953
At iterate    19  f =      -152.22  |proj g|=       0.89075
At iterate    20  f =      -152.24  |proj g|=       0.88303
At iterate    21  f =      -152.25  |proj g|=       0.11156
At iterate    22  f =      -152.25  |proj g|=      0.032457
At iterate    23  f =      -152.25  |proj g|=     0.0027982
At iterate    24  f =      -152.25  |proj g|=    7.2727e-05

iterations 24
function evaluations 28
segments explored during Cauchy searches 25
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 7.27273e-05
final function value -152.246

F = -152.246
final  value -152.246214 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -145.9  |proj g|=      0.33293
At iterate     1  f =      -147.85  |proj g|=       0.21885
At iterate     2  f =      -148.68  |proj g|=       0.14488
At iterate     3  f =      -148.77  |proj g|=       0.11888
At iterate     4  f =      -148.77  |proj g|=       0.16384
At iterate     5  f =      -148.77  |proj g|=      0.005448
At iterate     6  f =      -148.77  |proj g|=     0.0054473

iterations 6
function evaluations 10
segments explored during Cauchy searches 8
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.00544732
final function value -148.773

F = -148.773
final  value -148.773122 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -144.16  |proj g|=     0.022333
At iterate     1  f =      -144.34  |proj g|=       0.98514
At iterate     2  f =      -144.34  |proj g|=     0.0061448
At iterate     3  f =      -144.36  |proj g|=        0.9856
At iterate     4  f =      -144.45  |proj g|=       0.98646
At iterate     5  f =      -144.75  |proj g|=       0.98658
At iterate     6  f =      -145.45  |proj g|=       0.98247
At iterate     7  f =         -146  |proj g|=       0.97543
At iterate     8  f =      -146.67  |proj g|=       0.96521
At iterate     9  f =      -151.81  |proj g|=       0.91577
At iterate    10  f =      -151.81  |proj g|=       0.91595
At iterate    11  f =      -152.19  |proj g|=       0.13597
At iterate    12  f =      -152.24  |proj g|=       0.12648
At iterate    13  f =      -152.25  |proj g|=        0.6586
At iterate    14  f =      -152.25  |proj g|=      0.048059
At iterate    15  f =      -152.25  |proj g|=    0.00077927
At iterate    16  f =      -152.25  |proj g|=    2.1312e-05

iterations 16
function evaluations 38
segments explored during Cauchy searches 18
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 2.13118e-05
final function value -152.246

F = -152.246
final  value -152.246214 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -138.69  |proj g|=     0.041187
At iterate     1  f =      -140.92  |proj g|=     0.0060084
ys=-8.800e-01  -gs= 1.212e+00, BFGS update SKIPPED
At iterate     2  f =      -140.94  |proj g|=     0.0055703
At iterate     3  f =      -140.94  |proj g|=       0.99619
At iterate     4  f =      -140.94  |proj g|=     0.0055226
At iterate     5  f =      -140.94  |proj g|=     0.0063274

iterations 5
function evaluations 13
segments explored during Cauchy searches 7
BFGS updates skipped 1
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0063274
final function value -140.944

F = -140.944
final  value -140.944223 
converged

* The 5 best values (multistart) obtained are:
 -152.2334 -152.2462 -148.7731 -152.2462 -140.9442 
* The model corresponding to the best one (-152.2462) is stored. 
Warning message:
executing %dopar% sequentially: no parallel backend registered 
>  
>  #plot(m)
>  #m
>  
>  #Return model paramaters
>  maxLL = -m@logLik
>  intercept = m@trend.coef
>  nugget = m@covariance@nugget
>  theta = m@covariance@range.val
>     model = data.frame(intercept, nugget, maxLL, theta)
> 
>  #Cross validation (leave one out)
>  LOO = leaveOneOut.km(m, "SK",trend.reestim = TRUE)
>  
>  
> ## Kriging prediction surface ##
> x = seq(from = 0, to = (sizexy[1,2]-1)*40, by = 40)
> y = seq(from = 0, to = (sizexy[1,1]-1)*40, by = 40)
> grid = expand.grid(X1=x, X2 = y)
> pred.m = predict(m,grid,"SK")
> 
> 
> pred = matrix(pred.m$mean, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> lower95 = matrix(pred.m$lower95, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> upper95 = matrix(pred.m$upper95, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> 
> 
> writeMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/kriging.mat',
+          pred=pred, lower95=lower95, upper95=upper95, model = model, LOO = LOO,
+          fixNames=TRUE, matVersion="5", onWrite=NULL, verbose=FALSE)
> #  writeMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/kriging.mat',
> #           pred=pred, lower95=lower95, upper95=upper95, model = model, LOO = LOO,
> #           fixNames=TRUE, matVersion="5", onWrite=NULL, verbose=FALSE)
> 
> ## Install and load rgl package
> #library(rgl)
> 
> ## Plot surface and observations
> #plot3d(utm[,1],utm[,2],res, xlim=c(0,3000),ylim=c(0,3000),zlim=0:1)
> #surface3d(x,y, matrix(pred.m$mean,length(x),length(y)),col="light blue", alpha=0.5)
> 
> ## Plot surface and observations with intervals
> #  rglwidget()
> #plot3d(utm[,1],utm[,2],res, xlim=c(0,3000),ylim=c(0,3000),zlim=0:1)
> #surface3d(x,y, matrix(pred.m$mean, sizexy[1,1], sizexy[1,2]),col="light blue", alpha=0.5)
> #surface3d(x.grid,x.grid, matrix(pred.m$upper95,n.grid,n.grid),col="light blue", alpha=0.25)
> #surface3d(x.grid,x.grid, matrix(pred.m$lower95,n.grid,n.grid),col="light blue", alpha=0.25)
> #rgl.snapshot("filename.png")
> 
> proc.time()
   user  system elapsed 
  2.012   0.020   2.029 
