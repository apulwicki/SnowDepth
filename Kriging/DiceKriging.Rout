
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ############################################################################
> #Dice Kriging
> ############################################################################
> 
> ## Libraries
> library(R.matlab)
R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help.

Attaching package: ‘R.matlab’

The following objects are masked from ‘package:base’:

    getOption, isOpen

> library(DiceKriging)
> library(DiceOptim)
> library(foreach)
> 
> 
> ## Load my data ##
> #residuals = readMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/residuals.mat')
> residuals = readMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/residuals.mat')
> res = residuals$res
> utm = data.frame(residuals$utm)
> sizexy = residuals$sizexy
> 
> ## Model ##
> m = km(~1,design = utm, response = res, covtype = "matern5_2", nugget.estim = TRUE, multistart = 5, iso = TRUE)

optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern5_2 
  - nugget : unknown homogenous nugget effect 
  - parameters lower bounds :  1e-10 
  - parameters upper bounds :  5767.017 
  - upper bound for alpha   :  1 
  - best initial criterion value(s) :  49.68885 49.61676 49.55967 49.55056 49.46524 

N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.689  |proj g|=      0.65155
At iterate     1  f =       -49.73  |proj g|=      0.039316
At iterate     2  f =       -49.73  |proj g|=     0.0042756
At iterate     3  f =       -49.73  |proj g|=    4.2127e-05
At iterate     4  f =       -49.73  |proj g|=    5.1856e-05

iterations 4
function evaluations 8
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 5.18561e-05
final function value -49.7297

F = -49.7297
final  value -49.729671 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.617  |proj g|=       0.5642
At iterate     1  f =      -49.696  |proj g|=       0.46359
At iterate     2  f =      -49.702  |proj g|=      0.027243
At iterate     3  f =      -49.702  |proj g|=    0.00071106
At iterate     4  f =      -49.702  |proj g|=    9.5761e-05

iterations 4
function evaluations 6
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 9.57607e-05
final function value -49.7023

F = -49.7023
final  value -49.702314 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       -49.56  |proj g|=        0.484
At iterate     1  f =      -49.588  |proj g|=     0.0053818
At iterate     2  f =      -49.588  |proj g|=       0.00014
At iterate     3  f =      -49.588  |proj g|=    0.00014002

iterations 3
function evaluations 7
segments explored during Cauchy searches 4
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000140023
final function value -49.5877

F = -49.5877
final  value -49.587660 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.551  |proj g|=      0.45839
At iterate     1  f =      -49.569  |proj g|=      0.008063
At iterate     2  f =      -49.569  |proj g|=    0.00014162
At iterate     3  f =      -49.569  |proj g|=    0.00014164

iterations 3
function evaluations 6
segments explored during Cauchy searches 4
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000141636
final function value -49.5688

F = -49.5688
final  value -49.568840 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.465  |proj g|=      0.47308
At iterate     1  f =      -49.531  |proj g|=      0.089539
At iterate     2  f =      -49.531  |proj g|=     0.0037476
At iterate     3  f =      -49.531  |proj g|=    0.00014312
At iterate     4  f =      -49.531  |proj g|=    0.00021072

iterations 4
function evaluations 9
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000210719
final function value -49.5313

F = -49.5313
final  value -49.531272 
converged

* The 5 best values (multistart) obtained are:
 -49.72967 -49.70231 -49.58766 -49.56884 -49.53127 
* The model corresponding to the best one (-49.72967) is stored. 
Warning message:
executing %dopar% sequentially: no parallel backend registered 
>  
>  #plot(m)
>  #m
>  
>  #Return model paramaters
>  maxLL = -m@logLik
>  intercept = m@trend.coef
>  nugget = m@covariance@nugget
>  theta = m@covariance@range.val
>     model = data.frame(intercept, nugget, maxLL, theta)
> 
>  #Cross validation (leave one out)
>  LOO = leaveOneOut.km(m, "SK",trend.reestim = TRUE)
>  
>  
> ## Kriging prediction surface ##
> x = seq(from = 0, to = (sizexy[1,2]-1)*40, by = 40)
> y = seq(from = 0, to = (sizexy[1,1]-1)*40, by = 40)
> grid = expand.grid(X1=x, X2 = y)
> pred.m = predict(m,grid,"SK")
> 
> 
> pred = matrix(pred.m$mean, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> lower95 = matrix(pred.m$lower95, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> upper95 = matrix(pred.m$upper95, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> 
> 
> writeMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/kriging.mat',
+          pred=pred, lower95=lower95, upper95=upper95, model = model, LOO = LOO,
+          fixNames=TRUE, matVersion="5", onWrite=NULL, verbose=FALSE)
> #  writeMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/kriging.mat',
> #           pred=pred, lower95=lower95, upper95=upper95, model = model, LOO = LOO,
> #           fixNames=TRUE, matVersion="5", onWrite=NULL, verbose=FALSE)
> 
> ## Install and load rgl package
> #library(rgl)
> 
> ## Plot surface and observations
> #plot3d(utm[,1],utm[,2],res, xlim=c(0,3000),ylim=c(0,3000),zlim=0:1)
> #surface3d(x,y, matrix(pred.m$mean,length(x),length(y)),col="light blue", alpha=0.5)
> 
> ## Plot surface and observations with intervals
> #  rglwidget()
> #plot3d(utm[,1],utm[,2],res, xlim=c(0,3000),ylim=c(0,3000),zlim=0:1)
> #surface3d(x,y, matrix(pred.m$mean, sizexy[1,1], sizexy[1,2]),col="light blue", alpha=0.5)
> #surface3d(x.grid,x.grid, matrix(pred.m$upper95,n.grid,n.grid),col="light blue", alpha=0.25)
> #surface3d(x.grid,x.grid, matrix(pred.m$lower95,n.grid,n.grid),col="light blue", alpha=0.25)
> #rgl.snapshot("filename.png")
> 
> proc.time()
   user  system elapsed 
  1.224   0.028   1.251 
