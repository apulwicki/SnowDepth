
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ############################################################################
> #Dice Kriging
> ############################################################################
> 
> ## Libraries
> library(R.matlab)
R.matlab v3.6.1 (2016-10-19) successfully loaded. See ?R.matlab for help.

Attaching package: ‘R.matlab’

The following objects are masked from ‘package:base’:

    getOption, isOpen

> library(DiceKriging)
> library(DiceOptim)
> library(foreach)
> 
> 
> ## Load my data ##
> #residuals = readMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/residuals.mat')
> residuals = readMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/residuals.mat')
> res = residuals$res
> utm = data.frame(residuals$utm)
> sizexy = residuals$sizexy
> 
> ## Model ##
> m = km(~1,design = utm, response = res, covtype = "matern5_2", nugget.estim = TRUE, multistart = 5, iso = TRUE)

optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern5_2 
  - nugget : unknown homogenous nugget effect 
  - parameters lower bounds :  1e-10 
  - parameters upper bounds :  5767.017 
  - upper bound for alpha   :  1 
  - best initial criterion value(s) :  49.8432 49.71119 49.52224 49.37131 49.35627 

N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.843  |proj g|=      0.62175
At iterate     1  f =      -49.884  |proj g|=       0.24621
At iterate     2  f =      -49.885  |proj g|=     0.0081016
At iterate     3  f =      -49.885  |proj g|=    0.00013596
At iterate     4  f =      -49.885  |proj g|=    0.00013597

iterations 4
function evaluations 7
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000135969
final function value -49.8854

F = -49.8854
final  value -49.885433 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.711  |proj g|=      0.44666
At iterate     1  f =       -49.77  |proj g|=         0.111
At iterate     2  f =       -49.77  |proj g|=     0.0069716
At iterate     3  f =       -49.77  |proj g|=    0.00014309
At iterate     4  f =       -49.77  |proj g|=    0.00017689

iterations 4
function evaluations 8
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000176889
final function value -49.7699

F = -49.7699
final  value -49.769946 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.522  |proj g|=      0.68882
At iterate     1  f =      -49.976  |proj g|=      0.022026
At iterate     2  f =      -49.976  |proj g|=    0.00052432
At iterate     3  f =      -49.976  |proj g|=    9.1363e-05

iterations 3
function evaluations 5
segments explored during Cauchy searches 4
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 9.13634e-05
final function value -49.9757

F = -49.9757
final  value -49.975655 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.371  |proj g|=      0.60601
At iterate     1  f =      -49.795  |proj g|=       0.29451
At iterate     2  f =      -49.797  |proj g|=     0.0030784
At iterate     3  f =      -49.797  |proj g|=    0.00014316
At iterate     4  f =      -49.797  |proj g|=    0.00014318

iterations 4
function evaluations 7
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000143179
final function value -49.7971

F = -49.7971
final  value -49.797143 
converged
N = 2, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -49.356  |proj g|=      0.78918
At iterate     1  f =      -49.872  |proj g|=       0.20802
At iterate     2  f =      -49.873  |proj g|=      0.062685
At iterate     3  f =      -49.874  |proj g|=      0.000215
At iterate     4  f =      -49.874  |proj g|=    0.00013793

iterations 4
function evaluations 6
segments explored during Cauchy searches 5
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.000137929
final function value -49.8735

F = -49.8735
final  value -49.873539 
converged

* The 5 best values (multistart) obtained are:
 -49.88543 -49.76995 -49.97566 -49.79714 -49.87354 
* The model corresponding to the best one (-49.97566) is stored. 
Warning message:
executing %dopar% sequentially: no parallel backend registered 
>  
>  #plot(m)
>  #m
>  
>  #Return model paramaters
>  maxLL = -m@logLik
>  intercept = m@trend.coef
>  nugget = m@covariance@nugget
>  theta = m@covariance@range.val
>     model = data.frame(intercept, nugget, maxLL, theta)
> 
>  #Cross validation (leave one out)
>  LOO = leaveOneOut.km(m, "SK",trend.reestim = TRUE)
>  
>  
> ## Kriging prediction surface ##
> x = seq(from = 0, to = (sizexy[1,2]-1)*40, by = 40)
> y = seq(from = 0, to = (sizexy[1,1]-1)*40, by = 40)
> grid = expand.grid(X1=x, X2 = y)
> pred.m = predict(m,grid,"SK")
> 
> 
> pred = matrix(pred.m$mean, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> lower95 = matrix(pred.m$lower95, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> upper95 = matrix(pred.m$upper95, sizexy[1,1], sizexy[1,2], byrow = TRUE)
> 
> 
> writeMat('/home/glaciology1/Documents/Data/SnowDepth/Kriging/kriging.mat',
+          pred=pred, lower95=lower95, upper95=upper95, model = model, LOO = LOO,
+          fixNames=TRUE, matVersion="5", onWrite=NULL, verbose=FALSE)
> #  writeMat('/Users/Alexandra/Documents/SFU/Data/SnowDepth/Kriging/kriging.mat',
> #           pred=pred, lower95=lower95, upper95=upper95, model = model, LOO = LOO,
> #           fixNames=TRUE, matVersion="5", onWrite=NULL, verbose=FALSE)
> 
> ## Install and load rgl package
> #library(rgl)
> 
> ## Plot surface and observations
> #plot3d(utm[,1],utm[,2],res, xlim=c(0,3000),ylim=c(0,3000),zlim=0:1)
> #surface3d(x,y, matrix(pred.m$mean,length(x),length(y)),col="light blue", alpha=0.5)
> 
> ## Plot surface and observations with intervals
> #  rglwidget()
> #plot3d(utm[,1],utm[,2],res, xlim=c(0,3000),ylim=c(0,3000),zlim=0:1)
> #surface3d(x,y, matrix(pred.m$mean, sizexy[1,1], sizexy[1,2]),col="light blue", alpha=0.5)
> #surface3d(x.grid,x.grid, matrix(pred.m$upper95,n.grid,n.grid),col="light blue", alpha=0.25)
> #surface3d(x.grid,x.grid, matrix(pred.m$lower95,n.grid,n.grid),col="light blue", alpha=0.25)
> #rgl.snapshot("filename.png")
> 
> proc.time()
   user  system elapsed 
  1.320   0.040   1.358 
